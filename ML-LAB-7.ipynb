{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e089423d",
      "metadata": {
        "id": "e089423d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfcases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # clinical information"
      ],
      "metadata": {
        "id": "CpULEtqksjB2"
      },
      "id": "CpULEtqksjB2",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e2b1da19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2b1da19",
        "outputId": "da845bbf-c839-43d5-bc32-575d07bc9110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        # Initialize weights\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "\n",
        "        # Initialize the biases\n",
        "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.bias_output = np.zeros((1, self.output_size))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        # Input to hidden\n",
        "        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_activation)\n",
        "\n",
        "        # Hidden to output\n",
        "        self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.predicted_output = self.sigmoid(self.output_activation)\n",
        "\n",
        "        return self.predicted_output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Compute the output layer error\n",
        "        output_error = y.reshape(-1, 1) - self.predicted_output  # Ensure y matches the output dimensions\n",
        "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output)\n",
        "\n",
        "        # Compute hidden layer error\n",
        "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update the weights and biases\n",
        "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate,conv=0.2):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.feedforward(X)\n",
        "            self.backward(X, y, learning_rate)\n",
        "            loss = np.mean(np.square(y - output))\n",
        "            if conv>loss:\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "height = dfcases[\"height\"].values\n",
        "weight = dfcases[\"weight\"].values\n",
        "bmi = dfcases[\"bmi\"].values\n",
        "X = np.array([[y,x] for x,y in zip(height,weight)])\n",
        "y = np.array([i for i in bmi])\n",
        "\n",
        "\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)\n",
        "nn.train(X, y, epochs=1000, learning_rate=0.1,conv=0.002)\n",
        "\n",
        "output  = nn.feedforward(X)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "param_distributions_mlp = {\n",
        "    'hidden_layer_sizes': [(50,)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "    'alpha': [0.002, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "    'max_iter': [100, 500, 1000],\n",
        "    'tol': [1e-3, 1e-4, 1e-5]\n",
        "}\n",
        "\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(6,), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "\n",
        "\n",
        "\n",
        "random_search_mlp = RandomizedSearchCV(\n",
        "    estimator=mlp,\n",
        "    param_distributions=param_distributions_mlp,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# Prepare your data - Ensure y is classification-friendly (binary/multi-class labels)\n",
        "height = dfcases[\"height\"].values\n",
        "weight = dfcases[\"weight\"].values\n",
        "bmi = dfcases[\"bmi\"].values\n",
        "X = np.array([[y,x] for x,y in zip(height, weight)])\n",
        "y = np.digitize(bmi, bins=[18.5, 24.9])  # Example: Converting BMI to categorical (binary)\n",
        "\n",
        "random_search_mlp.fit(X, y)\n",
        "\n",
        "# Print best hyperparameters and scores\n",
        "print(\"Best Perceptron Hyperparameters:\", random_search_perceptron.best_params_)\n",
        "print(\"Best Perceptron Accuracy:\", random_search_perceptron.best_score_)\n",
        "print(\"\\n\")\n",
        "print(\"Best MLP Hyperparameters:\", random_search_mlp.best_params_)\n",
        "print(\"Best MLP Accuracy:\", random_search_mlp.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBHy93Avzjkb",
        "outputId": "4819739d-17ae-4037-c958-1ad468f098cc"
      },
      "id": "OBHy93Avzjkb",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   5.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   5.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   4.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   4.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.4s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   5.6s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=  16.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=  10.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=  15.4s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   4.0s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   3.4s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   3.5s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   4.2s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   0.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.7s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.9s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   5.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.7s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   1.9s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.9s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.4s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.3s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.8s\n",
            "Best Perceptron Hyperparameters: {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 100, 'alpha': 0.001}\n",
            "Best Perceptron Accuracy: 0.7318443682192346\n",
            "\n",
            "\n",
            "Best MLP Hyperparameters: {'tol': 1e-05, 'solver': 'lbfgs', 'max_iter': 1000, 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'alpha': 0.001, 'activation': 'logistic'}\n",
            "Best MLP Accuracy: 0.9658743901676832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fe43ac6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe43ac6d",
        "outputId": "df67ce40-82e4-455e-c14e-d5f8c5d41457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [ 67.5 160.2], Target: 26, Prediction: 25\n",
            "Input: [ 54.8 167.3], Target: 19, Prediction: 19\n",
            "Input: [ 69.7 169.1], Target: 24, Prediction: 24\n",
            "Input: [ 53.  160.6], Target: 20, Prediction: 20\n",
            "Input: [ 59.7 171. ], Target: 20, Prediction: 20\n",
            "Input: [ 54.6 150. ], Target: 24, Prediction: 24\n",
            "Input: [ 62.3 167.7], Target: 22, Prediction: 21\n",
            "Input: [ 67.25 156.7 ], Target: 27, Prediction: 25\n",
            "Input: [ 50.9 157.9], Target: 20, Prediction: 20\n",
            "Input: [ 62.75 162.5 ], Target: 23, Prediction: 23\n",
            "Input: [ 81.45 175.4 ], Target: 26, Prediction: 25\n",
            "Input: [ 81.4 169.2], Target: 28, Prediction: 26\n",
            "Input: [ 64.9 153. ], Target: 27, Prediction: 25\n",
            "Input: [ 80.  177.9], Target: 25, Prediction: 25\n",
            "Input: [ 48.3 158. ], Target: 19, Prediction: 19\n",
            "Input: [ 68.9 162.3], Target: 26, Prediction: 25\n",
            "Input: [ 53.  164.2], Target: 19, Prediction: 19\n",
            "Input: [ 56.9 155. ], Target: 23, Prediction: 23\n",
            "Input: [ 66.2 171.3], Target: 22, Prediction: 22\n",
            "Input: [ 61.3 173.6], Target: 20, Prediction: 20\n",
            "Input: [ 61.6 155.1], Target: 25, Prediction: 25\n",
            "Input: [ 54.6 162. ], Target: 20, Prediction: 20\n",
            "Input: [ 47.8 139.4], Target: 24, Prediction: 24\n",
            "Input: [ 65.  161.8], Target: 24, Prediction: 24\n",
            "Input: [ 80.2 169.7], Target: 27, Prediction: 26\n",
            "Input: [ 62.6 169.7], Target: 21, Prediction: 21\n",
            "Input: [ 43.35 143.2 ], Target: 21, Prediction: 21\n",
            "Input: [ 49.9 148.9], Target: 22, Prediction: 22\n",
            "Input: [ 57.4 156.1], Target: 23, Prediction: 23\n",
            "Input: [ 57.6 166.4], Target: 20, Prediction: 20\n",
            "Input: [ 53.8 162.8], Target: 20, Prediction: 20\n",
            "Input: [ 71.9 169.4], Target: 25, Prediction: 25\n",
            "Input: [ 88.  171.8], Target: 29, Prediction: 26\n",
            "Input: [ 66.6 150.5], Target: 29, Prediction: 26\n",
            "Input: [ 50.4 155.2], Target: 20, Prediction: 21\n",
            "Input: [ 50.2 155.6], Target: 20, Prediction: 20\n",
            "Input: [ 82.75 180.5 ], Target: 25, Prediction: 25\n",
            "Input: [ 72.3 170.1], Target: 25, Prediction: 24\n",
            "Input: [ 64.7 162.5], Target: 24, Prediction: 24\n",
            "Input: [ 83.2 160.1], Target: 32, Prediction: 26\n",
            "Input: [ 78.7 175. ], Target: 25, Prediction: 25\n",
            "Input: [ 72.5 166.7], Target: 26, Prediction: 25\n",
            "Input: [ 52.9 172.4], Target: 17, Prediction: 18\n",
            "Input: [ 59.9 175.8], Target: 19, Prediction: 20\n",
            "Input: [ 50.  147.9], Target: 22, Prediction: 23\n",
            "Input: [ 53.75 150.7 ], Target: 23, Prediction: 23\n",
            "Input: [ 48.7 167.1], Target: 17, Prediction: 18\n",
            "Input: [ 56.2 160.3], Target: 21, Prediction: 21\n",
            "Input: [ 67.5 165.8], Target: 24, Prediction: 24\n",
            "Input: [ 51.6 158.1], Target: 20, Prediction: 20\n",
            "Input: [ 55.3 165.5], Target: 20, Prediction: 20\n",
            "Input: [ 67.3 173.5], Target: 22, Prediction: 22\n",
            "Input: [ 66.1 167.7], Target: 23, Prediction: 23\n",
            "Input: [ 71.9 165. ], Target: 26, Prediction: 25\n",
            "Input: [ 59.2 175.1], Target: 19, Prediction: 19\n",
            "Input: [ 50.3 157.9], Target: 20, Prediction: 20\n",
            "Input: [ 69.7 169.4], Target: 24, Prediction: 24\n",
            "Input: [ 57.8 169.7], Target: 20, Prediction: 20\n",
            "Input: [ 79.4 166. ], Target: 28, Prediction: 26\n",
            "Input: [ 46.8 157. ], Target: 19, Prediction: 18\n",
            "Input: [ 57.3 165.7], Target: 20, Prediction: 20\n",
            "Input: [ 62.4 161.5], Target: 23, Prediction: 23\n",
            "Input: [ 62.7 165.8], Target: 22, Prediction: 22\n"
          ]
        }
      ],
      "source": [
        "\n",
        "height = dfcases[\"height\"].values\n",
        "weight = dfcases[\"weight\"].values\n",
        "bmi = dfcases[\"bmi\"].values\n",
        "X = np.array([[y,x] for x,y in zip(height,weight)])\n",
        "y = np.array([i for i in bmi])\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='lbfgs', max_iter=10000000000000000)\n",
        "y = y.astype('int')\n",
        "mlp.fit(X, y)\n",
        "for i in range(len(X)//100):\n",
        "    prediction = mlp.predict([X[i]])[0]\n",
        "    print(f\"Input: {X[i]}, Target: {y[i]}, Prediction: {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # A2. Use cross-validation techniques (RandomizedSearchCV()) technique to tune the hyperparameters for your perceptron and MLP networks."
      ],
      "metadata": {
        "id": "0HNOqPmBxJyL"
      },
      "id": "0HNOqPmBxJyL"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNDubiMksG-M"
      },
      "id": "BNDubiMksG-M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_tuning():\n",
        "    param_distributions_perceptron = {\n",
        "    'penalty': ['l2'],  # Perceptron only supports 'l2'\n",
        "    'alpha': [0.001, 0.01, 0.1],  # Keep a reasonable range\n",
        "    'max_iter': [100, 500, 1000],\n",
        "    'tol': [1e-3, 1e-4, 1e-5]\n",
        "    }\n",
        "    perceptron = Perceptron(random_state=0)\n",
        "    random_search_perceptron = RandomizedSearchCV(\n",
        "    estimator=perceptron,\n",
        "    param_distributions=param_distributions_perceptron,\n",
        "    n_iter=10,  # Number of parameter settings to sample\n",
        "    cv=5,  # Cross-validation folds\n",
        "    scoring='accuracy',  # Evaluation metric\n",
        "    verbose=2,  # Output verbosity level\n",
        "    random_state=0\n",
        "    )\n",
        "    # Prepare your data - Ensure y is classification-friendly (binary/multi-class labels)\n",
        "    height = dfcases[\"height\"].values\n",
        "    weight = dfcases[\"weight\"].values\n",
        "    bmi = dfcases[\"bmi\"].values\n",
        "    X = np.array([[y,x] for x,y in zip(height, weight)])\n",
        "    y = np.digitize(bmi, bins=[18.5, 24.9])  # Example: Converting BMI to categorical (binary)\n",
        "\n",
        "    # Fit the models with RandomizedSearchCV\n",
        "    random_search_perceptron.fit(X, y)\n",
        "    return random_search_perceptron.best_params_,random_search_perceptron.best_score_\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGchSx5tunAF"
      },
      "id": "bGchSx5tunAF",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_tuning():\n",
        "\n",
        "\n",
        "    param_distributions_for_mlp = {\n",
        "        'hidden_layer_sizes': [(50,)],\n",
        "        'activation': ['relu', 'tanh', 'logistic'],\n",
        "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "        'alpha': [0.002, 0.001, 0.01],\n",
        "        'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "        'max_iter': [100, 500, 1000],\n",
        "        'tol': [1e-3, 1e-4, 1e-5]\n",
        "    }\n",
        "\n",
        "\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(6,), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "\n",
        "\n",
        "\n",
        "    random_search_mlp = RandomizedSearchCV(\n",
        "        estimator=mlp,\n",
        "        param_distributions=param_distributions_mlp,\n",
        "        n_iter=10,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        verbose=2,\n",
        "        random_state=0\n",
        "    )\n",
        "\n",
        "    # Prepare your data - Ensure y is classification-friendly (binary/multi-class labels)\n",
        "    height = dfcases[\"height\"].values\n",
        "    weight = dfcases[\"weight\"].values\n",
        "    bmi = dfcases[\"bmi\"].values\n",
        "    X = np.array([[y,x] for x,y in zip(height, weight)])\n",
        "    y = np.digitize(bmi, bins=[18.5, 24.9])  # Example: Converting BMI to categorical (binary)\n",
        "\n",
        "    random_search_mlp.fit(X, y)\n",
        "    return random_search_mlp.best_params_,random_search_mlp.best_score_\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3NzT-pik1V2L"
      },
      "id": "3NzT-pik1V2L",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kQKAlhx2PDQ"
      },
      "id": "7kQKAlhx2PDQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tabulate your results with various other classifiers such as Support Vector Machines, Decision Tree, RandomForest, CatBoost, AdaBoost, XGBoost, Naïve-Bayes. Tabulate your results for your problem using different performance metrics"
      ],
      "metadata": {
        "id": "8UG4zaT54Kdl"
      },
      "id": "8UG4zaT54Kdl"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "def A3():\n",
        "    height = dfcases[\"height\"].values\n",
        "    weight = dfcases[\"weight\"].values\n",
        "    bmi = dfcases[\"bmi\"].values\n",
        "    X = np.array([[y,x] for x,y in zip(height, weight)])\n",
        "    y = np.digitize(bmi, bins=[18.5, 24.9])\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Set up classifiers\n",
        "    model_collection = {\n",
        "        'Perceptron': Perceptron(**random_search_perceptron.best_params_, random_state=42),\n",
        "        'MLP': MLPClassifier(**random_search_mlp.best_params_, random_state=42),\n",
        "        'SVM': SVC(random_state=42),\n",
        "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(random_state=42),\n",
        "        'CatBoost': CatBoostClassifier(random_state=42, verbose=False),\n",
        "        'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "        'XGBoost': XGBClassifier(random_state=42, objective='multi:softprob'),\n",
        "        'Naive Bayes': GaussianNB()\n",
        "    }\n",
        "\n",
        "    # Define etrics\n",
        "    eval_metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "\n",
        "    # Get results matrix\n",
        "    results_df = pd.DataFrame(columns=['Model'] + eval_metrics)\n",
        "\n",
        "    # Training every model\n",
        "    for model_name, model in model_collection.items():\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate performance stats\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, average='macro')\n",
        "        rec = recall_score(y_test, y_pred, average='macro')\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "        fresh_results = pd.DataFrame({'Model': [model_name],\n",
        "                                      'Accuracy': [acc],\n",
        "                                      'Precision': [prec],\n",
        "                                      'Recall': [rec],\n",
        "                                      'F1-score': [f1]})\n",
        "        results_df = pd.concat([results_df, fresh_results], ignore_index=True)\n",
        "\n",
        "\n",
        "    return results_df\n"
      ],
      "metadata": {
        "id": "RV5z9nhg3H1_"
      },
      "id": "RV5z9nhg3H1_",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    best_params, score = perceptron_tuning()\n",
        "    print(\"Best Perceptron Hyperparameters:\", best_params)\n",
        "    print(\"Best Perceptron Accuracy:\", score)\n",
        "\n",
        "    best_params, score = mlp_tuning()\n",
        "    print(\"Best MLP Hyperparameters:\", best_params)\n",
        "    print(\"Best MLP Accuracy:\", score)\n",
        "    results = A3()\n",
        "    print(results)"
      ],
      "metadata": {
        "id": "WTcWsq9v18ad"
      },
      "id": "WTcWsq9v18ad",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-N7S3Xwf4rLZ"
      },
      "id": "-N7S3Xwf4rLZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOIdlzT62HKr",
        "outputId": "03d276f8-ab63-44da-b304-4a2e8c6a88d6"
      },
      "id": "TOIdlzT62HKr",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=1000, penalty=l2, tol=0.001; total time=   0.1s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ....alpha=0.01, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.01, max_iter=1000, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.2s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ...alpha=0.001, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ....alpha=0.01, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=500, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END ...alpha=0.01, max_iter=500, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END ....alpha=0.1, max_iter=100, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.0s\n",
            "[CV] END .....alpha=0.1, max_iter=100, penalty=l2, tol=1e-05; total time=   0.1s\n",
            "Best Perceptron Hyperparameters: {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 100, 'alpha': 0.001}\n",
            "Best Perceptron Accuracy: 0.7318443682192346\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=  14.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=1e-05; total time=   6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=adam, tol=1e-05; total time=   3.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   5.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=  10.8s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=lbfgs, tol=0.0001; total time=   2.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=  16.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=  15.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   2.0s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=lbfgs, tol=1e-05; total time=   5.1s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   5.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=  10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   2.5s\n",
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=lbfgs, tol=0.001; total time=  10.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=100, solver=sgd, tol=0.001; total time=   3.0s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.0s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   2.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   5.8s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   1.7s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=500, solver=sgd, tol=0.0001; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=invscaling, max_iter=100, solver=sgd, tol=0.0001; total time=   1.2s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.4s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.5s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.7s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.4s\n",
            "[CV] END activation=relu, alpha=0.002, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=500, solver=sgd, tol=1e-05; total time=   0.9s\n",
            "Best MLP Hyperparameters: {'tol': 0.001, 'solver': 'lbfgs', 'max_iter': 500, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (50,), 'alpha': 0.002, 'activation': 'logistic'}\n",
            "Best MLP Accuracy: 0.9627383722853959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-23-abadb460d6b6>:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, fresh_results], ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Model  Accuracy  Precision    Recall  F1-score\n",
            "0     Perceptron  0.662754   0.548325  0.387205  0.354146\n",
            "1            MLP  0.935837   0.914702  0.850884  0.877491\n",
            "2            SVM  0.970266   0.972376  0.916647  0.941421\n",
            "3  Decision Tree  0.987480   0.984362  0.982701  0.983518\n",
            "4  Random Forest  0.992175   0.994932  0.979788  0.987137\n",
            "5       CatBoost  0.989045   0.980866  0.986077  0.983438\n",
            "6       AdaBoost  0.718310   0.862928  0.542068  0.583505\n",
            "7        XGBoost  0.982786   0.972937  0.965440  0.969112\n",
            "8    Naive Bayes  0.748044   0.720717  0.590909  0.628476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i2as3VO513J",
        "outputId": "6ea425fa-b94b-44b5-ac07-5ab58b22cc0e"
      },
      "id": "-i2as3VO513J",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFJ4Nmsj4vPU"
      },
      "id": "fFJ4Nmsj4vPU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}